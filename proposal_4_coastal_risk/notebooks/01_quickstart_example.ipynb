{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Coastal Risk Framework - Quick Start\n",
    "\n",
    "This notebook demonstrates the basic workflow for coastal risk assessment using the integrated framework.\n",
    "\n",
    "## Workflow Overview:\n",
    "\n",
    "1. Load and process hazard data\n",
    "2. Build Bayesian network for compound hazards\n",
    "3. Generate scenario ensemble\n",
    "4. Run agent-based vulnerability model\n",
    "5. Perform uncertainty analysis\n",
    "6. Identify robust adaptation strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import framework modules\n",
    "from src.data_processing import CoastalDataProcessor\n",
    "from src.bayesian_network import CompoundHazardNetwork\n",
    "from src.agent_based_model import VulnerabilityModel\n",
    "from src.uncertainty import DeepUncertaintyAnalysis\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "\n",
    "Load historical hazard data for our target city (Lagos, Nigeria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = CoastalDataProcessor(city='Lagos', data_dir='../data/raw')\n",
    "\n",
    "# Load hazard data\n",
    "hazard_data = processor.load_hazard_data(\n",
    "    start_year=2000,\n",
    "    end_year=2023,\n",
    "    variables=['sea_level', 'storm_surge', 'precipitation', 'wave_height']\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(hazard_data)} days of data\")\n",
    "print(f\"Data quality score: {processor.data_quality_score:.2f}\")\n",
    "hazard_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize historical trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "hazard_data.plot(x='date', y='sea_level', ax=axes[0, 0], title='Sea Level')\n",
    "hazard_data.plot(x='date', y='storm_surge', ax=axes[0, 1], title='Storm Surge')\n",
    "hazard_data.plot(x='date', y='precipitation', ax=axes[1, 0], title='Precipitation')\n",
    "hazard_data.plot(x='date', y='wave_height', ax=axes[1, 1], title='Wave Height')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vulnerability data\n",
    "vulnerability_data = processor.load_vulnerability_data()\n",
    "print(f\"\\nLoaded vulnerability data for {len(vulnerability_data)} zones\")\n",
    "vulnerability_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayesian Network Construction\n",
    "\n",
    "Build a Bayesian network to model dependencies between hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bayesian network\n",
    "hazard_types = ['storm_surge', 'sea_level', 'precipitation']\n",
    "\n",
    "bn = CompoundHazardNetwork(\n",
    "    hazard_types=hazard_types,\n",
    "    city='Lagos',\n",
    "    use_hierarchical=True\n",
    ")\n",
    "\n",
    "# Visualize network structure\n",
    "bn.visualize_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit network to data\n",
    "print(\"Fitting Bayesian network... (this may take a few minutes)\")\n",
    "\n",
    "bn.fit(\n",
    "    data=hazard_data,\n",
    "    n_samples=1000,  # Reduced for quick demo\n",
    "    tune=500,\n",
    "    chains=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View parameter estimates\n",
    "summary = bn.get_summary_statistics()\n",
    "print(\"\\nParameter Estimates:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scenario Generation\n",
    "\n",
    "Generate ensemble of compound hazard scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scenarios\n",
    "scenarios = bn.sample_scenarios(\n",
    "    n_scenarios=100,  # Small number for demo\n",
    "    future_year=2050  # Project to 2050\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(scenarios)} compound hazard scenarios\")\n",
    "scenarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scenario distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, hazard in enumerate(hazard_types):\n",
    "    if hazard in scenarios.columns:\n",
    "        axes[i].hist(scenarios[hazard], bins=30, alpha=0.7, edgecolor='black')\n",
    "        axes[i].set_xlabel(hazard.replace('_', ' ').title())\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].set_title(f'{hazard.replace(\"_\", \" \").title()} Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate compound event probability\n",
    "thresholds = {\n",
    "    'storm_surge': 0.5,  # 0.5m\n",
    "    'sea_level': 100,     # 100mm\n",
    "    'precipitation': 50   # 50mm\n",
    "}\n",
    "\n",
    "compound_prob = bn.get_compound_probability(thresholds)\n",
    "print(f\"\\nProbability of compound event exceeding thresholds: {compound_prob:.3f}\")\n",
    "print(f\"Return period: ~{1/compound_prob:.1f} scenarios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent-Based Vulnerability Model\n",
    "\n",
    "Simulate household-level impacts and adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ABM\n",
    "abm = VulnerabilityModel(\n",
    "    city='Lagos',\n",
    "    n_households=1000,  # Small number for demo\n",
    "    spatial_resolution=100,  # 100m grid cells\n",
    "    width=50,\n",
    "    height=50,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Initialized ABM with {abm.n_households} household agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for scenario subset\n",
    "print(\"Running agent-based simulation...\")\n",
    "\n",
    "results = abm.run(\n",
    "    scenarios=scenarios.head(10),  # First 10 scenarios for demo\n",
    "    n_steps=30  # 30 days per scenario\n",
    ")\n",
    "\n",
    "print(\"\\nSimulation complete!\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot by scenario\n",
    "for scenario_id in results['scenario_id'].unique()[:3]:  # First 3 scenarios\n",
    "    scenario_data = results[results['scenario_id'] == scenario_id]\n",
    "\n",
    "    axes[0, 0].plot(scenario_data.index, scenario_data['Total_Damage'], label=f'Scenario {scenario_id}')\n",
    "    axes[0, 1].plot(scenario_data.index, scenario_data['Displaced_Households'], label=f'Scenario {scenario_id}')\n",
    "    axes[1, 0].plot(scenario_data.index, scenario_data['Adaptation_Rate'], label=f'Scenario {scenario_id}')\n",
    "    axes[1, 1].plot(scenario_data.index, scenario_data['Average_Risk_Perception'], label=f'Scenario {scenario_id}')\n",
    "\n",
    "axes[0, 0].set_title('Total Economic Damage')\n",
    "axes[0, 1].set_title('Displaced Households')\n",
    "axes[1, 0].set_title('Adaptation Rate')\n",
    "axes[1, 1].set_title('Average Risk Perception')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time Step')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vulnerability map\n",
    "vulnerability_map = abm.get_spatial_vulnerability_map()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(vulnerability_map, cmap='YlOrRd', origin='lower')\n",
    "plt.colorbar(label='Vulnerability Score')\n",
    "plt.title('Spatial Vulnerability Distribution')\n",
    "plt.xlabel('X coordinate')\n",
    "plt.ylabel('Y coordinate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deep Uncertainty Analysis\n",
    "\n",
    "Identify robust adaptation strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize uncertainty analysis\n",
    "rdm = DeepUncertaintyAnalysis(\n",
    "    n_scenarios=100,\n",
    "    objectives=['minimize_casualties', 'minimize_economic_loss']\n",
    ")\n",
    "\n",
    "# Define uncertain factors\n",
    "uncertain_factors = {\n",
    "    'slr_rate': (3, 10),           # mm/year\n",
    "    'storm_frequency': (2, 6),     # events/year\n",
    "    'population_growth': (0.02, 0.05),  # annual rate\n",
    "    'adaptation_cost_multiplier': (0.5, 2.0)\n",
    "}\n",
    "\n",
    "# Generate uncertainty space\n",
    "uncertainty_scenarios = rdm.generate_uncertainty_space(uncertain_factors)\n",
    "print(f\"Generated {len(uncertainty_scenarios)} scenarios in uncertainty space\")\n",
    "uncertainty_scenarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define adaptation strategies\n",
    "strategies = [\n",
    "    {\n",
    "        'name': 'Seawall',\n",
    "        'cost': 50000000,  # $50M\n",
    "        'protection_level': 0.8,\n",
    "        'implementation_time': 3\n",
    "    },\n",
    "    {\n",
    "        'name': 'Nature-based Solutions',\n",
    "        'cost': 20000000,  # $20M\n",
    "        'protection_level': 0.5,\n",
    "        'implementation_time': 2\n",
    "    },\n",
    "    {\n",
    "        'name': 'Managed Retreat',\n",
    "        'cost': 30000000,  # $30M\n",
    "        'protection_level': 1.0,  # Full protection (moved away)\n",
    "        'implementation_time': 5\n",
    "    },\n",
    "    {\n",
    "        'name': 'No Action',\n",
    "        'cost': 0,\n",
    "        'protection_level': 0.0,\n",
    "        'implementation_time': 0\n",
    "    }\n",
    "]\n",
    "\n",
    "for strategy in strategies:\n",
    "    rdm.define_adaptation_strategy(\n",
    "        name=strategy['name'],\n",
    "        actions=[{'protection_level': strategy['protection_level']}],\n",
    "        cost=strategy['cost'],\n",
    "        implementation_time=strategy['implementation_time']\n",
    "    )\n",
    "\n",
    "print(f\"Defined {len(strategies)} adaptation strategies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results and Recommendations\n",
    "\n",
    "Summary of key findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"COASTAL RISK ASSESSMENT SUMMARY - LAGOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. DATA QUALITY\")\n",
    "print(f\"   Overall Score: {processor.data_quality_score:.2f}/1.00\")\n",
    "print(f\"   Recommendation: {processor._recommend_approach()}\")\n",
    "\n",
    "print(f\"\\n2. HAZARD SCENARIOS\")\n",
    "print(f\"   Total scenarios generated: {len(scenarios)}\")\n",
    "print(f\"   Compound event probability: {compound_prob:.3f}\")\n",
    "print(f\"   Mean sea level (2050): {scenarios['sea_level'].mean():.1f} mm\")\n",
    "print(f\"   Mean storm surge: {scenarios['storm_surge'].mean():.2f} m\")\n",
    "\n",
    "print(f\"\\n3. VULNERABILITY ASSESSMENT\")\n",
    "print(f\"   Households simulated: {abm.n_households}\")\n",
    "print(f\"   Average adaptation rate: {results['Adaptation_Rate'].mean():.2%}\")\n",
    "print(f\"   Average risk perception: {results['Average_Risk_Perception'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\n4. ADAPTATION STRATEGIES\")\n",
    "for strategy in strategies:\n",
    "    print(f\"   - {strategy['name']}: ${strategy['cost']:,.0f}, Protection: {strategy['protection_level']:.0%}\")\n",
    "\n",
    "print(f\"\\n5. KEY RECOMMENDATIONS\")\n",
    "print(f\"   - Implement multi-layered adaptation approach\")\n",
    "print(f\"   - Prioritize nature-based solutions for cost-effectiveness\")\n",
    "print(f\"   - Enhance community risk awareness and preparedness\")\n",
    "print(f\"   - Monitor sea level trends for adaptive management\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Refine Analysis**: Run with more scenarios and longer simulation periods\n",
    "2. **Validate Results**: Compare with historical flood events\n",
    "3. **Stakeholder Engagement**: Present findings to city planners\n",
    "4. **Expand Coverage**: Apply to other coastal cities\n",
    "5. **Real-time Integration**: Connect to operational early warning systems\n",
    "\n",
    "For detailed documentation, see:\n",
    "- `docs/methodology.md`: Complete methodology\n",
    "- `docs/data_requirements.md`: Data specifications\n",
    "- API documentation: Generated using Sphinx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
